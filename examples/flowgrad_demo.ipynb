{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŒŠ FlowGrad v0.4 â€” Complete Demo\n",
                "\n",
                "**Training Diagnostics, Feature Engineering, Compression, Saliency, Quantization, Knowledge Distillation & LoRA/PEFT.**\n",
                "\n",
                "Run all cells in order."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install FlowGrad (Colab / fresh env)\n",
                "# !pip install git+https://github.com/hw01931/FlowGrad.git\n",
                "# !pip install torch xgboost lightgbm scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import flowgrad\n",
                "flowgrad.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 1: PyTorch FlowTracker â€” DL Training Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "from flowgrad import FlowTracker\n",
                "\n",
                "# Simple model\n",
                "model = nn.Sequential(\n",
                "    nn.Linear(20, 64),\n",
                "    nn.BatchNorm1d(64),\n",
                "    nn.ReLU(),\n",
                "    nn.Dropout(0.3),\n",
                "    nn.Linear(64, 32),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(32, 1),\n",
                ")\n",
                "\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
                "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
                "\n",
                "tracker = FlowTracker(\n",
                "    model,\n",
                "    optimizer=optimizer,\n",
                "    scheduler=scheduler,\n",
                "    run_name=\"exp_01_baseline\"\n",
                ")\n",
                "\n",
                "# Simulate training\n",
                "X = torch.randn(128, 20)\n",
                "y = torch.randn(128, 1)\n",
                "\n",
                "for epoch in range(50):\n",
                "    pred = model(X)\n",
                "    loss = nn.MSELoss()(pred, y)\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "    scheduler.step()\n",
                "    optimizer.zero_grad()\n",
                "    tracker.step(loss=loss.item())\n",
                "\n",
                "tracker.report()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visual dashboard\n",
                "tracker.plot.full_report()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 2: AI Agent Mode â€” Structured XML Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export training context as XML for AI assistants\n",
                "xml = tracker.export_for_agent(save=False)\n",
                "print(xml)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 3: Dynamic Saliency â€” Intelligent Pruning Priority"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import SaliencyAnalyzer\n",
                "\n",
                "sa = SaliencyAnalyzer(tracker)\n",
                "sa.report()\n",
                "\n",
                "# Individual analyses\n",
                "print(\"\\n--- Velocity Saliency ---\")\n",
                "for name, score in sa.velocity_saliency().items():\n",
                "    print(f\"  {name}: {score:.3f}\")\n",
                "\n",
                "print(\"\\n--- Gradient Momentum ---\")\n",
                "for name, slope in sa.gradient_momentum().items():\n",
                "    trend = \"declining â†“\" if slope < 0 else \"growing â†‘\"\n",
                "    print(f\"  {name}: {slope:.6f} ({trend})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 4: Quantization Advisor â€” Mixed-Precision Guidance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import QuantizationAdvisor\n",
                "\n",
                "qa = QuantizationAdvisor(tracker)\n",
                "qa.report()\n",
                "\n",
                "print(\"\\n--- Mixed-Precision Plan ---\")\n",
                "for layer, bits in qa.recommend_mixed_precision().items():\n",
                "    print(f\"  {layer}: {bits}-bit\")\n",
                "\n",
                "print(f\"\\nEstimated savings: {qa.estimated_size_reduction()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 5: Model Compression â€” Auto Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import CompressionTracker\n",
                "\n",
                "# Create a fresh model for compression\n",
                "comp_model = nn.Sequential(\n",
                "    nn.Linear(20, 64),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(64, 32),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(32, 1),\n",
                ")\n",
                "\n",
                "# Train it\n",
                "opt = torch.optim.Adam(comp_model.parameters(), lr=0.01)\n",
                "for _ in range(30):\n",
                "    pred = comp_model(X)\n",
                "    loss = nn.MSELoss()(pred, y)\n",
                "    loss.backward()\n",
                "    opt.step()\n",
                "    opt.zero_grad()\n",
                "\n",
                "# Compression eval function\n",
                "def eval_fn(m):\n",
                "    with torch.no_grad():\n",
                "        pred = m(X)\n",
                "        return -nn.MSELoss()(pred, y).item()  # higher = better\n",
                "\n",
                "comp = CompressionTracker(comp_model, eval_fn=eval_fn)\n",
                "result = comp.auto_compress(performance_floor=0.95)\n",
                "comp.report()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 6: Knowledge Distillation â€” Teacher-Student Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import DistillationTracker\n",
                "\n",
                "# Teacher (large) and Student (small)\n",
                "teacher = nn.Sequential(\n",
                "    nn.Linear(20, 128), nn.ReLU(),\n",
                "    nn.Linear(128, 64), nn.ReLU(),\n",
                "    nn.Linear(64, 1),\n",
                ")\n",
                "student = nn.Sequential(\n",
                "    nn.Linear(20, 32), nn.ReLU(),\n",
                "    nn.Linear(32, 16), nn.ReLU(),\n",
                "    nn.Linear(16, 1),\n",
                ")\n",
                "\n",
                "t_tracker = FlowTracker(teacher, run_name=\"teacher\")\n",
                "s_tracker = FlowTracker(student, run_name=\"student\")\n",
                "\n",
                "# Train teacher\n",
                "t_opt = torch.optim.Adam(teacher.parameters(), lr=0.01)\n",
                "for _ in range(30):\n",
                "    pred = teacher(X)\n",
                "    loss = nn.MSELoss()(pred, y)\n",
                "    loss.backward()\n",
                "    t_opt.step()\n",
                "    t_opt.zero_grad()\n",
                "    t_tracker.step(loss=loss.item())\n",
                "\n",
                "# Train student with KD\n",
                "s_opt = torch.optim.Adam(student.parameters(), lr=0.01)\n",
                "for _ in range(30):\n",
                "    with torch.no_grad():\n",
                "        t_out = teacher(X)\n",
                "    s_out = student(X)\n",
                "    task_loss = nn.MSELoss()(s_out, y)\n",
                "    kd_loss = nn.MSELoss()(s_out, t_out)\n",
                "    loss = 0.5 * task_loss + 0.5 * kd_loss\n",
                "    loss.backward()\n",
                "    s_opt.step()\n",
                "    s_opt.zero_grad()\n",
                "    s_tracker.step(loss=loss.item())\n",
                "\n",
                "dt = DistillationTracker(t_tracker, s_tracker)\n",
                "dt.report()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Suggested KD loss weights (higher = student struggles more there)\n",
                "weights = dt.suggest_distillation_weights()\n",
                "print(\"Suggested KD loss weights per layer:\")\n",
                "for layer, w in weights.items():\n",
                "    print(f\"  {layer}: {w:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 7: LoRA / PEFT Diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import PEFTTracker\n",
                "\n",
                "# Simulate a model with LoRA-style adapters\n",
                "class LoRAModel(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.base = nn.Linear(20, 64)\n",
                "        self.lora_A = nn.Linear(20, 4, bias=False)  # Low-rank\n",
                "        self.lora_B = nn.Linear(4, 64, bias=False)   # Low-rank\n",
                "        self.head = nn.Linear(64, 1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        h = self.base(x) + self.lora_B(self.lora_A(x))\n",
                "        return self.head(torch.relu(h))\n",
                "\n",
                "lora_model = LoRAModel()\n",
                "lora_tracker = FlowTracker(lora_model, run_name=\"lora_exp\")\n",
                "\n",
                "# Freeze base, only train LoRA\n",
                "for p in lora_model.base.parameters():\n",
                "    p.requires_grad = False\n",
                "\n",
                "lora_opt = torch.optim.Adam(filter(lambda p: p.requires_grad, lora_model.parameters()), lr=0.01)\n",
                "for _ in range(30):\n",
                "    pred = lora_model(X)\n",
                "    loss = nn.MSELoss()(pred, y)\n",
                "    loss.backward()\n",
                "    lora_opt.step()\n",
                "    lora_opt.zero_grad()\n",
                "    lora_tracker.step(loss=loss.item())\n",
                "\n",
                "pt = PEFTTracker(lora_tracker)\n",
                "pt.report()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rank recommendations\n",
                "ranks = pt.recommend_ranks()\n",
                "print(\"Recommended LoRA ranks:\")\n",
                "for layer, rank in sorted(ranks.items(), key=lambda x: -x[1]):\n",
                "    print(f\"  {layer}: rank={rank}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 8: XGBoost / Boosting Tracker"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import BoostingTracker\n",
                "from sklearn.datasets import make_classification\n",
                "\n",
                "X_cls, y_cls = make_classification(n_samples=500, n_features=10, random_state=42)\n",
                "\n",
                "try:\n",
                "    import xgboost as xgb\n",
                "    \n",
                "    bt = BoostingTracker()\n",
                "    dtrain = xgb.DMatrix(X_cls, label=y_cls, feature_names=[f'f{i}' for i in range(10)])\n",
                "    dval = xgb.DMatrix(X_cls[:100], label=y_cls[:100], feature_names=[f'f{i}' for i in range(10)])\n",
                "    \n",
                "    model = xgb.train(\n",
                "        {'max_depth': 4, 'eta': 0.1, 'objective': 'binary:logistic', 'eval_metric': 'logloss'},\n",
                "        dtrain,\n",
                "        num_boost_round=100,\n",
                "        evals=[(dtrain, 'train'), (dval, 'valid')],\n",
                "        callbacks=[bt.as_xgb_callback()],\n",
                "        verbose_eval=False,\n",
                "    )\n",
                "    bt.report()\n",
                "except ImportError:\n",
                "    print(\"XGBoost not installed â€” skipping.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 9: Feature Engineering + VIF"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from flowgrad import FeatureAnalyzer\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "import numpy as np\n",
                "\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf.fit(X_cls, y_cls)\n",
                "\n",
                "feature_names = [f'feature_{i}' for i in range(10)]\n",
                "analyzer = FeatureAnalyzer(rf, X_cls, y_cls, feature_names=feature_names)\n",
                "\n",
                "# Interactions\n",
                "interactions = analyzer.interactions(top_k=5)\n",
                "print(\"Top interactions:\")\n",
                "for item in interactions:\n",
                "    print(f\"  {item['feat_a']} Ã— {item['feat_b']}: synergy={item['synergy_score']:.4f}\")\n",
                "\n",
                "# Suggestions with VIF filter\n",
                "suggestions = analyzer.suggest_features(top_k=5, collinearity_check=True)\n",
                "print(\"\\nFeature suggestions (VIF-filtered):\")\n",
                "for s in suggestions:\n",
                "    print(f\"  {s['expression']}: lift={s['lift']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Section 10: All Agent XML Outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Each module can export its own XML section for AI agents\n",
                "print(\"=\" * 50)\n",
                "print(\"SALIENCY:\")\n",
                "print(sa.to_agent_xml())\n",
                "print()\n",
                "print(\"QUANTIZATION:\")\n",
                "print(qa.to_agent_xml())\n",
                "print()\n",
                "print(\"DISTILLATION:\")\n",
                "print(dt.to_agent_xml())\n",
                "print()\n",
                "print(\"PEFT:\")\n",
                "print(pt.to_agent_xml())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nðŸŽ‰ FlowGrad v0.5 â€” All features working!\")\n",
                "flowgrad.info()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
