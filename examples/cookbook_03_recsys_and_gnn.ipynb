{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<p align=\"center\">\n",
                "  <h1 align=\"center\">\ud83c\udf73 Cookbook 03: RecSys & GNN Health Monitoring</h1>\n",
                "  <p align=\"center\">\n",
                "    <strong>Diagnosing Embedding Collapse & GNN Over-Smoothing with GradTracer</strong>\n",
                "  </p>\n",
                "</p>\n",
                "\n",
                "---\n",
                "\n",
                "This recipe targets large-scale recommendation systems using Factorization Machines (FM), Matrix Factorization (MF), and Graph Neural Networks (GNN).\n",
                "\n",
                "We will demonstrate how GradTracer identifies two critical phenomenon:\n",
                "1. **Embedding Collapse (Zombie / Dead Neurons)** in standard MF/FM models.\n",
                "2. **Over-Smoothing (Variance Stagnation)** in GNN Message Passing layers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Load MovieLens-1M"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# !pip install gradtracer torch pandas numpy scipy requests tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import urllib.request\n",
                "import zipfile\n",
                "from gradtracer import FlowManager, EmbeddingTracker, FlowTracker\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "print(\"Downloading MovieLens-1M for scaled testing...\")\n",
                "url = \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
                "if not os.path.exists(\"ml-1m\"):\n",
                "    urllib.request.urlretrieve(url, \"ml-1m.zip\")\n",
                "    with zipfile.ZipFile(\"ml-1m.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\".\")\n",
                "\n",
                "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
                "df = pd.read_csv('ml-1m/ratings.dat', sep='::', names=columns, engine='python')\n",
                "\n",
                "# Implicit Feedback conversion (Rating >= 4 is positive)\n",
                "df = df[df['rating'] >= 4].copy()\n",
                "df['rating'] = 1.0\n",
                "\n",
                "df['user_id'] = df['user_id'].astype('category').cat.codes\n",
                "df['item_id'] = df['item_id'].astype('category').cat.codes\n",
                "num_users = df['user_id'].nunique()\n",
                "num_items = df['item_id'].max() + 1\n",
                "\n",
                "class ImplicitDataset(Dataset):\n",
                "    def __init__(self, df):\n",
                "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
                "        self.items = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
                "        self.labels = torch.ones(len(df), dtype=torch.float32)\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.users)\n",
                "        \n",
                "    def __getitem__(self, idx):\n",
                "        return self.users[idx], self.items[idx], self.labels[idx]\n",
                "\n",
                "train_loader = DataLoader(ImplicitDataset(df.sample(frac=0.8)), batch_size=1024, shuffle=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Tracking Matrix Factorization (Embedding Collapse)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FactorizationMachine(nn.Module):\n",
                "    def __init__(self, num_users, num_items, dim=64):\n",
                "        super().__init__()\n",
                "        self.user_emb = nn.Embedding(num_users, dim)\n",
                "        self.item_emb = nn.Embedding(num_items, dim)\n",
                "        \n",
                "        # Introduce bad initialization to force zombie behavior\n",
                "        nn.init.uniform_(self.user_emb.weight, -0.5, 0.5)\n",
                "        nn.init.uniform_(self.item_emb.weight, -0.5, 0.5)\n",
                "        \n",
                "    def forward(self, user, item):\n",
                "        return (self.user_emb(user) * self.item_emb(item)).sum(1)\n",
                "\n",
                "model_fm = FactorizationMachine(num_users, num_items).to(device)\n",
                "optimizer = torch.optim.Adam(model_fm.parameters(), lr=0.1) # Extremely high LR to force oscillation\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "\n",
                "manager = FlowManager()\n",
                "# We track BOTH embeddings\n",
                "manager.add_tracker(\"user\", EmbeddingTracker(model_fm.user_emb, name=\"U_Emb\", auto_fix=True))\n",
                "manager.add_tracker(\"item\", EmbeddingTracker(model_fm.item_emb, name=\"I_Emb\", auto_fix=True))\n",
                "\n",
                "model_fm.train()\n",
                "for i, (u, i_id, l) in enumerate(train_loader):\n",
                "    u, i_id, l = u.to(device), i_id.to(device), l.to(device)\n",
                "    optimizer.zero_grad()\n",
                "    preds = model_fm(u, i_id)\n",
                "    loss = criterion(preds, l)\n",
                "    loss.backward()\n",
                "    \n",
                "    manager.step()\n",
                "    optimizer.step()\n",
                "    \n",
                "    if i > 50: break\n",
                "    \n",
                "manager.report()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Detecting GNN Over-Smoothing (Experimental)\n",
                "For Graph Neural Networks (like LightGCN or GAT), GradTracer monitors the transformation layers. If the Gradient Norm / Variance of layer $(L)$ drops to near zero while $(L-1)$ is still active, it implies that message passing is washing out distinct node representations (Over-Smoothing)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleGNN(nn.Module):\n",
                "    def __init__(self, num_nodes, dim=64):\n",
                "        super().__init__()\n",
                "        self.emb = nn.Embedding(num_nodes, dim)\n",
                "        self.gcn1 = nn.Linear(dim, dim)\n",
                "        self.gcn2 = nn.Linear(dim, dim)\n",
                "        self.gcn3 = nn.Linear(dim, dim) # 3 Layers deep usually starts oversmoothing\n",
                "        \n",
                "    def forward(self, nodes):\n",
                "        # Simulating Message Passing heavily for demo\n",
                "        x = self.emb(nodes)\n",
                "        x = F.relu(self.gcn1(x))\n",
                "        x = F.relu(self.gcn2(x))\n",
                "        x = self.gcn3(x)\n",
                "        return x.sum(-1)\n",
                "\n",
                "gnn = SimpleGNN(num_users).to(device)\n",
                "gnn_tracker = FlowTracker(gnn, track_gradients=True)\n",
                "optimizer = torch.optim.Adam(gnn.parameters(), lr=0.01)\n",
                "\n",
                "gnn.train()\n",
                "for i, (u, _, _) in enumerate(train_loader):\n",
                "    u = u.to(device)\n",
                "    optimizer.zero_grad()\n",
                "    out = gnn(u)\n",
                "    loss = out.mean()\n",
                "    loss.backward()\n",
                "    gnn_tracker.step(loss.item())\n",
                "    optimizer.step()\n",
                "    if i > 25: break\n",
                "\n",
                "# Examine the layer variances\n",
                "print(\"\\n\\n=== GNN Over-Smoothing Check ===\")\n",
                "layer_stats = gnn_tracker.summary()\n",
                "for layer_name, stats in layer_stats.items():\n",
                "    if \"gcn\" in layer_name and \"weight\" in layer_name:\n",
                "        print(f\"{layer_name}: Health Score = {stats.get('health_score', 'N/A')}\")\n",
                "        if stats.get('health_score', 100) < 50:\n",
                "            print(f\"  \u26a0\ufe0f Early warning for over-smoothing detected in {layer_name}!\")\n",
                "        "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}